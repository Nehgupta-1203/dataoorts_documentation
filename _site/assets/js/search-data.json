{"0": {
    "doc": "Access Applications -- Tunnel",
    "title": "Access Applications Running In GC2 Via Tunneling",
    "content": "To access your application running in GC2 on any particular port using a local tunnel to make it publicly accessible, you can use any tunneling service. However, ensure that it is a trusted service since tunneling is a critical process that can introduce many vulnerabilities. We recommend using ngrok or cloudflare, In DMI, we have already installed ngrok and cloudflared services. Ngrok Tunnel . Ngrok Local Tunnel: https://dashboard.ngrok.com/ . Create Tunnel . # Download and Install Ngrok curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc \\ | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc &gt;/dev/null \\ &amp;&amp; echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" \\ | sudo tee /etc/apt/sources.list.d/ngrok.list \\ &amp;&amp; sudo apt update \\ &amp;&amp; sudo apt install ngrok . # Run the following command to add your authtoken to the default ngrok.yml, Get your authtoken here:https://dashboard.ngrok.com/get-started/your-authtoken ngrok config add-authtoken &lt;your-authtoken&gt; . # Let's suppose your application is running on port 8080, and you want to make that port publicly available ngrok http http://localhost:8080 . This command provides a publicly accessible URL that forwards traffic from your local machine‚Äôs port 8080. You can also view your tunnel details on Ngrok‚Äôs Agents dashboard https://dashboard.ngrok.com/tunnels/agents . Extra: Ngrok offers several third-party plugins that enhance tunnel analysis, improve security, and provide valuable insights for better usability. Cloudflared Tunnel . Cloudflared Tunnel: https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/ . Create Tunnel . # Let's suppose your application is running on port 8888, and you want to make that port publicly available ./cloudflared-linux-amd64 --url [http://localhost:8888](http://localhost:8888) . Example Output: . 2024-05-31T08:12:59Z INF Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps 2024-05-31T08:12:59Z INF Requesting new quick Tunnel on trycloudflare.com... 2024-05-31T08:13:00Z INF +--------------------------------------------------------------------------------------------+ 2024-05-31T08:13:00Z INF | Your quick Tunnel has been created! Visit it at (it may take some time to be reachable): | 2024-05-31T08:13:00Z INF | https://metro-impact-lands-ict.trycloudflare.com | 2024-05-31T08:13:00Z INF +--------------------------------------------------------------------------------------------+ 2024-05-31T08:13:00Z INF Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared] 2024-05-31T08:13:00Z INF Version 2024.5.0 2024-05-31T08:13:00Z INF GOOS: linux, GOVersion: go1.22.2, GoArch: amd64 2024-05-31T08:13:00Z INF Settings: map[ha-connections:1 protocol:quic url:http://localhost:8888] 2024-05-31T08:13:00Z INF cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/run-tunnel/as-a-service/ 2024-05-31T08:13:00Z INF Generated Connector ID: 332e5631-b7d2-478d-874f-289a9d01f1af 2024-05-31T08:13:00Z INF Initial protocol quic 2024-05-31T08:13:00Z INF ICMP proxy will use 172.28.0.12 as source for IPv4 2024-05-31T08:13:00Z INF ICMP proxy will use :: as source for IPv6 2024-05-31T08:13:00Z INF Starting metrics server on 127.0.0.1:42781/metrics 2024/05/31 08:13:00 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 2048 kiB, got: 416 kiB). See https://github.com/quic-go/quic-go/wiki/UDP-Buffer-Sizes for details. 2024-05-31T08:13:00Z INF Registered tunnel connection connIndex=0 connection=b22a9411-f190-41ec-8d40-27933bf07ae2 event=0 ip=198.41.192.7 location=sea01 protocol=quic . http://localhost:8888‚Äî- Public URL ‚Äî-&gt; https://metro-impact-lands-ict.trycloudflare.com . You can also forward GC2 ports to your localhost, but to do so, you need to configure the OpenSSH server in your GC2 instance. Below are some useful guides for setting this up: . | SSH GC2 Instance | Connect GC2 Locally | . ",
    "url": "/dataoorts_documentation/docs/access-applications/#access-applications-running-in-gc2-via-tunneling",
    
    "relUrl": "/docs/access-applications/#access-applications-running-in-gc2-via-tunneling"
  },"1": {
    "doc": "Access Applications -- Tunnel",
    "title": "Access Applications -- Tunnel",
    "content": " ",
    "url": "/dataoorts_documentation/docs/access-applications/",
    
    "relUrl": "/docs/access-applications/"
  },"2": {
    "doc": "AI Powered Email Verification",
    "title": "AI Powered Email Verification",
    "content": "Verify Emails Instantly and Extract Key Data‚ÄîPowered by AI . Quick Note: AI Mail Verification is a part of the Dataoorts AI-CRM Project. All data is securely managed and administered by Dataoorts. Email Verification, the Serverless Way ‚úî Zero commitments ‚Äì No subscriptions, no lock-ins ‚úî True‚Ä¶ . Potential Use Cases . Let‚Äôs move forward and explore the potential use cases of AI-powered email verification and data extractor. AI Powered Mails Verification By Dataoorts Revolutionize Your Outreach: The Power of AI in Email Verification and Data Extraction ‚Ä¶ . Register and Get Started . Introducing AI Email Verification‚ÄîManaged by Dataoorts , the trusted name behind high-performance GPU cloud computing. Experience cutting-edge email validation, built for speed, accuracy, and scalability. Step 1: Sign Up for Dataoorts &amp; Unlock‚Ä¶ . Single Email Verification . Complete Asynchronous Architecture: Experience blazing-fast API responses! Powered by async architecture, our system effortlessly manages thousands of concurrent requests. So that your apps stay quick, scalable, and frustration-free. 1. Try ‚Ä¶ . Bulk Email Verification . Current Limits for Bulk Email Verification: The maximum limit for a single batch of email verification is 50,000 emails or fewer. If you need to verify more than 50,000 emails, you can process them in multiple batches, with each batch conta‚Ä¶ . API For Email Verification . Asynchronous Architecture Our API features an async architecture, allowing you to handle multiple requests seamlessly and execute parallel operations efficiently. Multiple failed and unauthorized attempts will result in a permanent IP block‚Ä¶. FAQs . We have addressed common questions here, but if you need further assistance, Do not hesitate to contact us anytime at help@dataoorts.com . 1. How is the email holder name predicted? We‚Äôve trained a robust machine learning model on a vas‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/ai-emails-verification/",
    
    "relUrl": "/docs/ai-emails-verification/"
  },"3": {
    "doc": "AI Models Catalog",
    "title": "Inference Models Catalog",
    "content": "Currently, Dataoorts offers support for powerful text generation and text-to-image generation models, enabling you to create content and visuals with ease. Looking ahead, we‚Äôre excited to expand our platform with an even broader array of AI models to meet diverse needs and unlock more possibilities. Stay tuned for upcoming additions that will further enhance your AI toolkit! . Models Catalog Git Repo:https://github.com/DATAOORTS/dataoortai/blob/main/model.txt . Text to Text Generation Models ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.. * meta/llama-3.3-70b-instruct-fp8-fast * meta/llama-3.1-70b-instruct * meta/llama-3.1-8b-instruct * meta/llama-guard-3-8b * qwen/qwen1.5-14b-chat-awq * deepseek-ai/deepseek-math-7b-instruct * deepseek-ai/deepseek-r1-distill-qwen-32b * qwen/qwen2.5-coder-32b-instruct * qwen/qwq-32b * meta/llama-4-scout-17b-16e-instruct * google/gemma-3-12b-it Text to Image Generation Models ‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶..‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶‚Ä¶.. * stabilityai/stable-diffusion-xl-base-1.0 * bytedance/stable-diffusion-xl-lightning * lykon/dreamshaper-8-lcm * black-forest-labs/flux-1-schnell . Request Model . For any model requests, feel free to contact us at help@dataoorts.com. ",
    "url": "/dataoorts_documentation/docs/ai-models-catalog#inference-models-catalog",
    
    "relUrl": "/docs/ai-models-catalog#inference-models-catalog"
  },"4": {
    "doc": "AI Models Catalog",
    "title": "AI Models Catalog",
    "content": " ",
    "url": "/dataoorts_documentation/docs/ai-models-catalog",
    
    "relUrl": "/docs/ai-models-catalog"
  },"5": {
    "doc": "API For Email Verification",
    "title": "üëâ Get your Unify API KEY Here",
    "content": ". Our REST API enables AI-powered email verification and is compatible with any framework. For demonstration purposes, we have used Python as an example. ",
    "url": "/dataoorts_documentation/docs/api-email-verification/#-get-your-unify-api-key-here",
    
    "relUrl": "/docs/api-email-verification/#-get-your-unify-api-key-here"
  },"6": {
    "doc": "API For Email Verification",
    "title": "1. For Single Email Verification",
    "content": "API Endpoint URL: . https://cloud.dataoorts.com/ai_mails_api/v1 . # Health Check import requests URL = \"https://cloud.dataoorts.com/ai_mails_api/v1\" resp = requests.get(URL) print(resp.status_code, resp.json()) PythonCopy 200 {'status': 'All Services Operational'} . ‚û°Ô∏è Both Email Verification and Data Prediction . import requests, json # Set Everything URL = \"https://cloud.dataoorts.com/ai_mails_api/v1\" API_KEY = &lt;Your_Unify_API_Key&gt; response = requests.post( URL, headers={ \"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\" }, json={ \"email\": \"rajatvishwakarma3656@dataoorts.com\", \"info\": \"true\" } ) print(response.status_code) print(json.dumps(response.json(), indent=2)) . 200 { \"info\": { \"domain\": \"dataoorts.com\", \"email\": \"rajatvishwakarma3656@dataoorts.com\", \"email_avatar\": null, \"is_disposable\": false, \"is_free\": false, \"isv_domain\": true, \"isv_format\": true, \"isv_mx\": null, \"isv_noblock\": true, \"isv_nocatchall\": true, \"isv_nogeneric\": true, \"mx_record\": \"route1.mx.cloudflare.net\", \"provider\": null, \"result_cause\": \"no_connect\", \"test_result\": \"unknown\", \"test_score\": 40 }, \"user_info\": { \"accuracy\": 0.75, \"name\": \"Rajat Vishwakarma\", \"username\": \"rajatvishwakarma3656\" } } . ‚û°Ô∏è Only Email Verification . import requests, json # Set Everything URL = \"https://cloud.dataoorts.com/ai_mails_api/v1\" API_KEY = &lt;Your_Unify_API_Key&gt; response = requests.post( URL, headers={ \"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\" }, json={ \"email\": \"quantum.rjvishwa@gmail.com\", \"info\": \"false\" } ) print(response.status_code) print(json.dumps(response.json(), indent=2)) . 200 { \"info\": { \"domain\": \"gmail.com\", \"email\": \"quantum.rjvishwa@gmail.com\", \"email_avatar\": null, \"is_disposable\": false, \"is_free\": true, \"isv_domain\": true, \"isv_format\": true, \"isv_mx\": true, \"isv_noblock\": true, \"isv_nocatchall\": true, \"isv_nogeneric\": true, \"mx_record\": \"gmail-smtp-in.l.google.com\", \"provider\": \"gmail\", \"result_cause\": \"accepted_email\", \"test_result\": \"deliverable\", \"test_score\": 100 } } . ‚û°Ô∏è Only Email Data Prediction . API Endpoint URL: . https://cloud.dataoorts.com/ai_mails_api/data/v1 . import requests # Replace with your valid API key URL = \"https://cloud.dataoorts.com/ai_mails_api/data/v1\" HEADERS = {\"Authorization\": \"Bearer &lt;Your_Unify_API_Key&gt;\"} PAYLOAD = {\"email\": \"rajat696viswwakarrma@gmail.com\"} response = requests.post(URL, json=PAYLOAD, headers=HEADERS) print(\"Response JSON:\", response.json()) . Response JSON: {'user_info': {'accuracy': 0.81, 'name': 'Rajat Vishwakarma', 'username': 'rajat696viswwakarrma'}} . ",
    "url": "/dataoorts_documentation/docs/api-email-verification/#1-for-single-email-verification",
    
    "relUrl": "/docs/api-email-verification/#1-for-single-email-verification"
  },"7": {
    "doc": "API For Email Verification",
    "title": "2. For Bulk Email Verification",
    "content": "API Endpoint URL: . https://cloud.dataoorts.com/ai_mails_api/bulk/v1 . # Health Check - Endpoint import requests, json URL = \"https://cloud.dataoorts.com/ai_mails_api/bulk/v1\" resp = requests.get(URL) print(resp.status_code) print(json.dumps(resp.json(), indent=2)) . 200 { \"status\": \"All Services Operational\" } . ‚û°Ô∏è Submit and Queue the Batch Request . Current Limits for Bulk Email Verification: . | The maximum limit for a single batch of email verification is 50,000 emails or fewer. | If you need to verify more than 50,000 emails, you can process them in multiple batches, with each batch containing no more than 50,000 emails. | You may submit up to three batches per day under this default limit. ‚Üí Need a Higher Limit? This limit can be increased on a case-by-case basis. If you require a higher quota, please contact our team at help@dataoorts.com to request an &gt; increase. ‚Üí Single Email Verification: There are no limits for single email verification‚Äîverify as many emails as you need, asynchronously! | . import json, requests # Replace with your valid API key URL = \"https://cloud.dataoorts.com/ai_mails_api/bulk/v1\" API_KEY = &lt;Your_Unify_API_Key&gt; # Example batch of emails emails = [ \"alice@example.com\", \"bob@example.net\", \"carol@example.org\" ] response = requests.post( URL, headers={ \"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\" }, json={\"emails\": emails} ) # Ensure that you save the response unique batch ID, as it is volatile. print(response.status_code) print(json.dumps(response.json(), indent=2)) . 200 { \"id\": \"0KVBG3TK6QXFJKIYY6Z4ECA7AXZ\" } . ‚û°Ô∏è Retrieve the Batch Response Using its Unique ID . API Endpoint URL: . https://cloud.dataoorts.com/ai_mails_api/bulk_results/v1 . Multiple failed and unauthorized attempts to retrieve the batch response will result in a permanent IP block. import json, requests # Replace with your valid API key URL = \"https://cloud.dataoorts.com/ai_mails_api/bulk_results/v1\" API_KEY = &lt;Your_Unify_API_Key&gt; # Use the valid batch ID obtained from the batch submission response. payload = {\"id\": \"0KVBG3TK6QXFJKIYY6Z4ECA7AXZ\"} response = requests.post( URL, headers={ \"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\" }, json=payload ) print(response.status_code) print(json.dumps(response.json(), indent=2)) . 200 [ { \"domain\": \"example.org\", \"email\": \"carol@example.org\", \"email_avatar\": null, \"is_disposable\": false, \"is_free\": false, \"isv_domain\": true, \"isv_format\": true, \"isv_mx\": null, \"isv_noblock\": true, \"isv_nocatchall\": true, \"isv_nogeneric\": true, \"mx_record\": \"\", \"provider\": null, \"result_cause\": \"no_connect\", \"test_result\": \"unknown\", \"test_score\": 40, \"username\": \"carol\" }, { \"domain\": \"example.net\", \"email\": \"bob@example.net\", \"email_avatar\": null, \"is_disposable\": false, \"is_free\": false, \"isv_domain\": true, \"isv_format\": true, \"isv_mx\": null, \"isv_noblock\": true, \"isv_nocatchall\": true, \"isv_nogeneric\": true, \"mx_record\": \"\", \"provider\": null, \"result_cause\": \"no_connect\", \"test_result\": \"unknown\", \"test_score\": 40, \"username\": \"bob\" }, { \"domain\": \"example.com\", \"email\": \"alice@example.com\", \"email_avatar\": null, \"is_disposable\": true, \"is_free\": false, \"isv_domain\": true, \"isv_format\": true, \"isv_mx\": null, \"isv_noblock\": true, \"isv_nocatchall\": true, \"isv_nogeneric\": true, \"mx_record\": \"\", \"provider\": null, \"result_cause\": \"no_connect\", \"test_result\": \"unknown\", \"test_score\": 10, \"username\": \"alice\" } ] . Feedback on our API If you encounter any issues with the API, have feature requests, or want to share your thoughts, feel free to contact us at help@dataoorts.com. ",
    "url": "/dataoorts_documentation/docs/api-email-verification/#2-for-bulk-email-verification",
    
    "relUrl": "/docs/api-email-verification/#2-for-bulk-email-verification"
  },"8": {
    "doc": "API For Email Verification",
    "title": "API For Email Verification",
    "content": "Asynchronous Architecture . Our API features an async architecture, allowing you to handle multiple requests seamlessly and execute parallel operations efficiently. Multiple failed and unauthorized attempts will result in a permanent IP block. ",
    "url": "/dataoorts_documentation/docs/api-email-verification/",
    
    "relUrl": "/docs/api-email-verification/"
  },"9": {
    "doc": "Bulk Email Verification",
    "title": "To verify bulk emails, Visit Here and follow these steps:",
    "content": ". | Get Your API Key ‚Äì Obtain your Unify API key from Here and paste it into the API Section to validate your Dataoorts account. | Upload Your File ‚Äì Select the file containing the Emails(Less than 50K)‚ÄîUpload, then press Submit to begin processing. | . | Save Your Job ID ‚Äì After initial checks, your batch job ID will be returned, and your email-file will enter the processing queue. Since this ID is volatile due to enhanced security, Ensure you Save it somewhere in secure place for fetching the job result. | Wait Briefly ‚Äì Take a short break, Perhaps enjoy a cup of tea. | Retrieve Results ‚Äì Visit Here, Enter your Unify API Key and job ID, and access the verified emails in JSON format, ready for download. | . Developers: Bulk Email Verification API If you‚Äôre searching for an API, we also offer access to all our services with api, Including AI-powered bulk email verification. Get the API documentation Here. ",
    "url": "/dataoorts_documentation/docs/bulk-email-verification/#to-verify-bulk-emails-visit-here-and-follow-these-steps",
    
    "relUrl": "/docs/bulk-email-verification/#to-verify-bulk-emails-visit-here-and-follow-these-steps"
  },"10": {
    "doc": "Bulk Email Verification",
    "title": "Bulk Email Verification",
    "content": "Current Limits for Bulk Email Verification: . | The maximum limit for a single batch of email verification is 50,000 emails or fewer. | If you need to verify more than 50,000 emails, you can process them in multiple batches, with each batch containing no more than 50,000 emails. | You may submit up to three batches per day under this default limit. ‚Üí Need a Higher Limit? This limit can be increased on a case-by-case basis. If you require a higher quota, please contact our team at help@dataoorts.com to request an increase. ‚Üí Single Email Verification: There are no limits for single email verification‚Äîverify as many emails as you need, asynchronously! | . For interactive web-based bulk email verification, the currently accepted file types are TXT, XLSX, and CSV. If you need access to additional file types, please request it Here. Ensure that your file contains only a single column or single row of email addresses. The cost of email verification is $0.0001 per email. Ensure your account has sufficient balance for bulk email verification. ",
    "url": "/dataoorts_documentation/docs/bulk-email-verification/",
    
    "relUrl": "/docs/bulk-email-verification/"
  },"11": {
    "doc": "Cloud Instance API",
    "title": "Cloud Instance API",
    "content": "Coming soon . Complete Cloud API Docs Coming Soon‚Ä¶ [If you‚Äôre seeking access to Dataoorts AI API Model, head over to https://dataoorts.document360.io/docs/dataoorts-ai ] . ",
    "url": "/dataoorts_documentation/docs/cloud-api/",
    
    "relUrl": "/docs/cloud-api/"
  },"12": {
    "doc": "Connect GC2 Locally",
    "title": "Run GC2 Instance Locally",
    "content": "Note üìù . To run a GC2 instance locally, you need to set up the OpenSSH server manually on your GC2 instance. Here is the guide: SSH-GC2 . You can use local port forwarding for many applications to turn your local machine into an interface powered by a remote GC2 instance. This setup allows you to enjoy the comfort of your local environment while leveraging the acceleration of GPU compute. You can use several major services locally with the hardware acceleration of GC2, including: . | Google Colab | Deepnote | Jupyter | VS Code | PyCharm | RStudio | Matlab | TensorFlow | PyTorch | Apache Spark | AutoML tools | Unity 3D | GROMOS | LAMMPS | NAMD | AMBER | And many more‚Ä¶ | . # Forward the port &lt;abcd&gt; from your local machine to port &lt;wxyz&gt; on your remote GC2 machine # ssh -L &lt;abcd&gt;:localhost:&lt;wxyz&gt; user@node_ip -p &lt;node port forwarded to port 22 on GC2&gt; ssh -L &lt;abcd&gt;:localhost:&lt;wxyz&gt; user@node_ip -p &lt;node port forwarded to port 22 on GC2&gt; . # You can also forward multiple ports # ports to forward: &lt;abcd&gt; --&gt; &lt;wxyz&gt; &amp; &lt;ghij&gt; --&gt; &lt;pqrs&gt; ssh -L &lt;abcd&gt;:localhost:&lt;wxyz&gt; -L &lt;ghij&gt;:localhost:&lt;pqrs&gt; user@node_ip -p &lt;node port forwarded to port 22 on GC2&gt; . # Let's take an example # forward localhost port from: 7788 # to remote GC2 instance port: 9988 # GC2 instance user: root # GC2 instance node_ip: 24.56.84.12 # node port forwarded to port 22 on GC2: 24697 ssh -L 7788:localhost:9988 root@24.56.84.12 -p 24697 . ",
    "url": "/dataoorts_documentation/docs/connect-gc2-locally/#run-gc2-instance-locally",
    
    "relUrl": "/docs/connect-gc2-locally/#run-gc2-instance-locally"
  },"13": {
    "doc": "Connect GC2 Locally",
    "title": "Connect GC2 Locally",
    "content": " ",
    "url": "/dataoorts_documentation/docs/connect-gc2-locally/",
    
    "relUrl": "/docs/connect-gc2-locally/"
  },"14": {
    "doc": "Serverless Cloud API - Dataoorts AI",
    "title": "Serverless Cloud API - Dataoorts AI",
    "content": "Get Started . Dataoorts AI Dataoorts Serverless API Endpoint: https://cloud.dataoorts.com/api/v1 Get Your Serverless API Credential From:https://cloud.dataoorts.com/llms Unlock the power of serverless AI with Dataoorts! Gain seamless access ‚Ä¶ . AI Models Catalog . Inference Models Catalog Currently, Dataoorts offers support for powerful text generation and text-to-image generation models, enabling you to create content and visuals with ease. Looking ahead, we‚Äôre excited to expand our platform with an eve‚Ä¶ . Text Generation . 11 Articles . Image Generation . 4 Articles . ",
    "url": "/dataoorts_documentation/docs/dataoorts-ai/",
    
    "relUrl": "/docs/dataoorts-ai/"
  },"15": {
    "doc": "GC2 Instance Documentation",
    "title": "GC2 Instance Documentation",
    "content": "Get Started With GC2 GPU Instances . Launch GC2 Instance Here are steps to launch your first gc2 instance: step 1: Visit https://cloud.dataoorts.com/ Register your account and verify your email. step 2: Add sufficient credit amount to start your GC2 instance. step 3: Select the‚Ä¶ . GC2 Instance Features . Features of GC2 Instances GC2 Instances are purpose built for development purposes. They are lightweight yet powerful, offering fast and secure performance. These instances utilize DDRA technology and are updated weekly to enhance features and‚Ä¶ . SSH GC2 Instances . Access GC2 Instance ‚Äî SSH You can access our GC2 instance either directly through a browser or from your local machine. Ways to Access the GC2 Instance: Web Based Jupyter Terminal (Depreciated) SSH Web Based Terminal - Jupyter‚Ä¶ . Connect GC2 Locally . Run GC2 Instance Locally Note üìù To run a GC2 instance locally, you need to set up the OpenSSH server manually on your GC2 instance. Here is the guide: SSH-GC2 You can use local port forwarding for many applications to turn your loc‚Ä¶ . GC2 Instance Extent . GC2 Instance Restrictions We have implemented these limitations on our instances to ensure you can work confidently while we also enjoy our coffee time peacefully. Our security validation and limitation protocols have been thoroughly researched an‚Ä¶ . FAQs: GC2 Instance . GC2 Instance ‚Äî F.A.Qs What is DDRA ? Learn about DDRA Here . Where My GC2 Instance Hosted ? All GC2 instances are hosted within Dataoorts‚Äô globally distributed DDRA Cluster. As community-based instances, GC2 leverages dece‚Ä¶ . Access Applications ‚Äì Tunnel . Access Applications Running In GC2 Via Tunneling To access your application running in GC2 on any particular port using a local tunnel to make it publicly accessible, you can use any tunneling service. However, ensure that it is a trusted service‚Ä¶ . GC2: Docker . Using Docker In GC2 Instance We have now added Docker as one of the primary setups for the GC2 instance for all DMI. Hence, you have the latest version of Docker running. If you want to install a specific version of Docker, please follow the instru‚Ä¶ . GC2: Kubernetes . Get Started With K8s In GC2 Instance Setting up a Kubernetes cluster on a GC2 instance has been tested with KinD, Minikube, and Rancher K3s. Before setting up your Kubernetes environment, ensure you select Docker as the driver and configure it to u‚Ä¶ . KinD Cluster . KinD In GC2 [Linux] To Install KinD, You Need To Follow The Instructions Given Here: https://kind.sigs.k8s.io/docs/user/quick-start/ Install Kubectl [Linux] Follow These Instruction: https://kubernetes.io/docs/tasks/tools/install-kubectl-l‚Ä¶ . Minikube Cluster . Minikube In GC2 [Linux] # Download and Install Minikube # Set-Up Minikube Using the docker driver curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 sudo install minikube-linux-amd64 /usr/local/bin/minikube &amp;‚Ä¶ . GC2: Support . Get Support Related Software/Tools/Applications So far, GC2 supports all tools, software, and applications, but there are no limitations. Of course, we don‚Äôt check everything in particular. If you face any issues while running or installing anyth‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/development-cloud/",
    
    "relUrl": "/docs/development-cloud/"
  },"16": {
    "doc": "FAQs: GC2 Instance",
    "title": "GC2 Instance ‚Äî F.A.Qs",
    "content": "What is DDRA ? Learn about DDRA [Here](/why-and-how-dataoorts-gpu-cloud). Where My GC2 Instance Hosted ? All GC2 instances are hosted within Dataoorts' globally distributed DDRA Cluster. As community-based instances, GC2 leverages decentralized GPUs worldwide, ensuring robust isolation and a secure operating environment. All GC2 Instance Work on DDRA ? Yes. All GC2 Instances Works on DDRA What are RAMs and CPUs in Particular Instance ? RAMs and CPUs and all other resources are allocated dynamically. Is there any hidden charge ? No, what you see in the dashboard is it. GC2 Instance is VM or VMI ? Yes, You can say it Lite-VM, FYI we still working on KVM support. Can I use GC2 for Gaming ? Yes, You can. Can I mine Crypto In GC2 Instance ? No, we strictly prohibit any mining activity or any illegal activity. What if my balance goes down below the threshold point ? If your balance goes below $2.50, all running instances and pods are automatically scheduled for termination. So please maintain the minimum balance of $2.50 or above. Can we pause the instance rather than terminating it ? Currently, we are working on persistent storage for GC2 instances. We assure you that this will be supported very soon. What is DMI ? Learn about DMI [Here](/dmi). ",
    "url": "/dataoorts_documentation/docs/faqs-gc2-instance/#gc2-instance--faqs",
    
    "relUrl": "/docs/faqs-gc2-instance/#gc2-instance--faqs"
  },"17": {
    "doc": "FAQs: GC2 Instance",
    "title": "FAQs: GC2 Instance",
    "content": " ",
    "url": "/dataoorts_documentation/docs/faqs-gc2-instance/",
    
    "relUrl": "/docs/faqs-gc2-instance/"
  },"18": {
    "doc": "FAQs",
    "title": "F.A.Qs",
    "content": "We have addressed common questions here, but if you need further assistance, Do not hesitate to contact us anytime at help@dataoorts.com. How is the email holder name predicted? We‚Äôve trained a robust machine learning model on a vast corpus of email data to accurately estimate the likely name associated with an email address. The model uses advanced permutations and logic patterns that users often follow when creating their emails. While the predictions aren't always perfect, they offer a high degree of accuracy in most cases. For completely random or abstract email addresses, the system defaults to extracting the username portion. This helps reduce the chance of emails being flagged as spam, particularly when users don‚Äôt provide additional information during fast registrations. Our solution combines AI-driven name prediction with modern email verification to enhance deli Is there a usage limit? * **Single Email Verification**: No limits; processed asynchronously. * **Batch Email Verification**: You can send up to **three batches per day**, with each batch containing no more than **50,000 emails**. This limit is temporary and protects our system from abuse. If you need a higher limit, feel free to reach out to us at [help@dataoorts.com](help@dataoorts.com) ‚Äî we‚Äôll be happy to increase it.. What is the pricing structure? We believe in fairness and flexibility. There are **no recurring subscriptions or commitments ‚Äî just pay as you go**. You only pay for what you use. For detailed and up-to-date pricing, visit our pricing page: [https://mails.dataoorts.com/pricing](https://mails.dataoorts.com/pricing) How do I register for the service? This service is powered and maintained by Dataoorts. To use it, you‚Äôll need to [Sign up on the Dataoorts platform](https://cloud.dataoorts.com/register) and top-up a minimum balance. Once done, you can access our AI-powered Email Validation Service via the Dataoorts cloud dashboard. How can I contact support, and where can I find your Privacy Policy and Terms of Service? You can contact us anytime at [help@dataoorts.com](https://dataoorts.com). Our Privacy Policy and Terms of Service are the same as those for the Dataoorts platform. You can view them at: [https://dataoorts.com](https://dataoorts.com). ",
    "url": "/dataoorts_documentation/docs/faqs/#faqs",
    
    "relUrl": "/docs/faqs/#faqs"
  },"19": {
    "doc": "FAQs",
    "title": "FAQs",
    "content": " ",
    "url": "/dataoorts_documentation/docs/faqs/",
    
    "relUrl": "/docs/faqs/"
  },"20": {
    "doc": "GC2: Docker",
    "title": "Using Docker In GC2 Instance",
    "content": "We have now added Docker as one of the primary setups for the GC2 instance for all DMI. Hence, you have the latest version of Docker running. If you want to install a specific version of Docker, please follow the instructions given on the official Docker site,(https://docs.docker.com/engine/install/ubuntu/). Bonus: We have also installed and configured the latest version of the NVIDIA Container Toolkit with Docker for your convenience. Now you can run GPU-accessible containers by adding two flags: ‚Äìgpus and ‚Äìruntime=nvidia You can also install a specific version of the NVIDIA Container Toolkit from the official site: (https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html). ",
    "url": "/dataoorts_documentation/docs/gc2-docker/#using-docker-in-gc2-instance",
    
    "relUrl": "/docs/gc2-docker/#using-docker-in-gc2-instance"
  },"21": {
    "doc": "GC2: Docker",
    "title": "GC2: Docker",
    "content": " ",
    "url": "/dataoorts_documentation/docs/gc2-docker/",
    
    "relUrl": "/docs/gc2-docker/"
  },"22": {
    "doc": "GC2 Instance Extent",
    "title": "GC2 Instance Restrictions",
    "content": "We have implemented these limitations on our instances to ensure you can work confidently while we also enjoy our coffee time peacefully. Our security validation and limitation protocols have been thoroughly researched and cover nearly all use cases, allowing you to work without hassle. These measures primarily come into play when detecting malicious or illegal activities, such as crypto mining or intentional attempts to compromise our systems. Rest assured, your normal work won‚Äôt be affected by these safeguards. GC2 Limitations: . | Prohibition of Crypto Mining: Users are strictly prohibited from engaging in any form of cryptocurrency mining activities within our system. | Illicit Code and Interference: Users must refrain from running unsophisticated or illegal code or making intentional attempts to interfere with our host-node system. | Resource Allocation: While we cannot guarantee full GPU memory and threads availability at all times, users will receive their reserved quota. | AI Monitoring: All processes within the instance are subject to monitoring by our AI system. | Any Attempt to Security Breach/File System Modification: Any attempt to breach or bypass our system security measures or isolation protocols, or interfere with the host-node file system, is strictly prohibited. | Port Limitation: Opening more than five ports is not allowed. | Harmful Linux Commands: Users must refrain from running Linux commands that may cause hindrance or harm to the system, especially long bash scripts. | GPU Memory Utilization: Users are advised to use GPU memory judiciously, especially when running large models. Utilization of GPU memory should not exceed one-third of the total available memory of that particular GPU to ensure optimal performance and to avoid resource contention issues. | Process Limit: There is a limit on the number of processes users can start simultaneously. Instance . | Start Failure Notification: In case an instance fails to start but remains visible in the dashboard, users are required to notify us and delete the instance to avoid incurring additional costs. | Beta Testing Conditions: As we are currently in the beta phase, instances may be automatically terminated for updates or other reasons, albeit in rare cases. | . Users are expected to comply with these terms to ensure the smooth operation and security of the platform. Failure to adhere to these terms may result in the suspension or termination of user accounts and services. We reserve the right to take appropriate actions to enforce compliance and maintain the integrity and security of our platform. Security and Isolation . Our modern security protocols are designed to safeguard instances against security breaches and malicious or illegal activities. However, we are flexible and can modify these protocols to better serve your specific requirements. Please feel free to contact us at help@dataoorts.com with valid and well-informed reasons for any necessary modifications. ",
    "url": "/dataoorts_documentation/docs/gc2-instance-extent/#gc2-instance-restrictions",
    
    "relUrl": "/docs/gc2-instance-extent/#gc2-instance-restrictions"
  },"23": {
    "doc": "GC2 Instance Extent",
    "title": "GC2 Instance Extent",
    "content": " ",
    "url": "/dataoorts_documentation/docs/gc2-instance-extent/",
    
    "relUrl": "/docs/gc2-instance-extent/"
  },"24": {
    "doc": "GC2 Instance Features",
    "title": "Features of GC2 Instances",
    "content": "GC2 Instances are purpose built for development purposes. They are lightweight yet powerful, offering fast and secure performance. These instances utilize DDRA technology and are updated weekly to enhance features and performance while ensuring isolation and security. Accessible from nearly every country through Cloudflare‚Äôs CDN technology, GC2 Instances boast lightning-fast spin-up times, typically launching in seconds. Users can select their preferred DMI snapshot to initiate the instance. With a 99.9% uptime rate, GC2 Instances offer reliable performance, resulting in minimal latency for users. Each GC2 are continuously tracked to enhance robustness and protect against spamming or attacks, making them an excellent choice for AI development tasks. Regular Updates . GC2 Instances are updated on a weekly basis to enhance their features and performance. Fast . GC2 instances exhibit impressive speed and efficiency, making them ideal for executing AI tasks. Isolated and Secured . GC2 Instances works on DDRA technology and therefore, we consistently ensure that instances remain isolated and secured. Light Weight . GC2 Instances are lightweight compared to complete VMs but can perform nearly every task that VMs can handle. Globally Accessible . GC2 Instances are accessible from nearly every country, We are leveraging Cloudflare‚Äôs CDN technology. Spin Up In Seconds . GC2 Instances boast lightning-fast spin-up times, taking mere seconds to launch, which makes them incredibly efficient. Flexible and Customizable . GC2 instances utilize DMI snapshots for spinning-up, you have wide option to select your preferred DMI to initiate the instance. Negligible Latency . GC2 instances maintain a remarkable 99.99% uptime rate, ensuring minimal latency &amp; reliable performance for users. ",
    "url": "/dataoorts_documentation/docs/gc2-instance-features/#features-of-gc2-instances",
    
    "relUrl": "/docs/gc2-instance-features/#features-of-gc2-instances"
  },"25": {
    "doc": "GC2 Instance Features",
    "title": "GC2 Instance Features",
    "content": " ",
    "url": "/dataoorts_documentation/docs/gc2-instance-features/",
    
    "relUrl": "/docs/gc2-instance-features/"
  },"26": {
    "doc": "GC2: Kubernetes",
    "title": "Get Started With K8s In GC2 Instance",
    "content": "Setting up a Kubernetes cluster on a GC2 instance has been tested with KinD, Minikube, and Rancher K3s. Before setting up your Kubernetes environment, ensure you select Docker as the driver and configure it to use the GPU devices you want to make visible in your pods. | Setting Up Kubernetes via KinD . | Setting Up Kubernetes via Minikube . | Installing Kubectl . | . ",
    "url": "/dataoorts_documentation/docs/gc2-kubernetes/#get-started-with-k8s-in-gc2-instance",
    
    "relUrl": "/docs/gc2-kubernetes/#get-started-with-k8s-in-gc2-instance"
  },"27": {
    "doc": "GC2: Kubernetes",
    "title": "GC2: Kubernetes",
    "content": " ",
    "url": "/dataoorts_documentation/docs/gc2-kubernetes/",
    
    "relUrl": "/docs/gc2-kubernetes/"
  },"28": {
    "doc": "GC2: Support",
    "title": "Get Support Related Software/Tools/Applications",
    "content": "So far, GC2 supports all tools, software, and applications, but there are no limitations. Of course, we don‚Äôt check everything in particular. If you face any issues while running or installing anything on a GC2 instance, please report them to us immediately. We will take a look and try our best to make it work in the next update of GC2. You can reach out to us with as much information as you can through email: help@dataoorts.com . ",
    "url": "/dataoorts_documentation/docs/gc2-support/#get-support-related-softwaretoolsapplications",
    
    "relUrl": "/docs/gc2-support/#get-support-related-softwaretoolsapplications"
  },"29": {
    "doc": "GC2: Support",
    "title": "GC2: Support",
    "content": " ",
    "url": "/dataoorts_documentation/docs/gc2-support/",
    
    "relUrl": "/docs/gc2-support/"
  },"30": {
    "doc": "Get Started With GC2 GPU Instance",
    "title": "Launch GC2 Instance",
    "content": "Here are steps to launch your first gc2 instance: . step 1: Visit https://cloud.dataoorts.com/ Register your account and verify your email. step 2: Add sufficient credit amount to start your GC2 instance. step 3: Select the instance type you want to spin up. The first object is the GPU model, the second object is the total GPU memory, and the third object is the total number of GPUs in the instance. For example, ‚ÄòH100-80-1‚Äô means one Nvidia H100 GPU. For more specifications about GPU models, visit https://dataoorts.com/pricing/. step 4: Select your DMI (learn more about DMI: https://dataoorts.com/dmi/) and Launch Instance. step 5: To access your instance, we provide a Jupyter-based web SSH session. fyi, You can add your preferred method for accessing the instance. Note: While the instance is launching or terminating, do not close or refresh the browser. It will take a while to process everything. DDRA Cluster for Hosting GC2 Instances Nodes All GC2 instances are hosted within Dataoorts' globally distributed DDRA Cluster. As community-based instances, GC2 leverages decentralized GPUs worldwide, ensuring robust isolation and a secure operating environment. Report Issue/Bug . If you encounter any bugs or issues on our cloud platform, we sincerely appreciate your efforts and time in notifying us. Please feel free to reach out to us at help@dataoorts.com . ",
    "url": "/dataoorts_documentation/docs/gc2/#launch-gc2-instance",
    
    "relUrl": "/docs/gc2/#launch-gc2-instance"
  },"31": {
    "doc": "Get Started With GC2 GPU Instance",
    "title": "Get Started With GC2 GPU Instance",
    "content": " ",
    "url": "/dataoorts_documentation/docs/gc2/",
    
    "relUrl": "/docs/gc2/"
  },"32": {
    "doc": "Verify Emails Instantly and Extract Key Data‚ÄîPowered by AI",
    "title": "Get Started Instantly",
    "content": "1. ‚ö° Use our Web Dashboard - Beginner Friendly. | ‚úß Free Trial: https://mails.dataoorts.com (3 verifications per user) | ‚úß Unlimited Access: https://cloud.dataoorts.com/aicrm_mails (Hosted on Dataoorts) | . 2. ‚ú® API Integration ‚Äì Ideal for automated workflows and scalable solutions. | üöÄ One integration, endless possibilities | ‚úîÔ∏èHandles Multiple Requests Concurrently | ‚ö° Serverless pay-per-verification | üåê Global deliverability intelligence | üëâ Grab Your API Key Now | . Simple &amp; Transparent Pricing . | Plan | Price Per Email Verification | Features | . | Free Trial | $0.0000 | 3 free verifications per user | . | Basic Email Verification | $0.0001 | Standard email checks | . | AI-Powered Email Verification | $0.0002 | + AI data prediction linked with email | . | No subscriptions ‚Äì Pay per use | $0.20 minimum balance (threshold) | Unified credits ‚Äì Works across all Dataoorts services | Most Affordable &amp; Accurate Email Verification - Guaranteed | Credits never expires ‚Äì Use across our service ecosystem | . ‚Üí Price Calculator . Contact Sales . Custom Solutions Available! . Need enterprise volume, white-labeling, or unique workflows? . üì© Contact Our Sales Team: . | help@dataoorts.com | Fill out quick sales form | . ",
    "url": "/dataoorts_documentation/docs/verify-emails-instantly-and-extract-key-data-powered-by-ai#get-started-instantly",
    
    "relUrl": "/docs/verify-emails-instantly-and-extract-key-data-powered-by-ai#get-started-instantly"
  },"33": {
    "doc": "Verify Emails Instantly and Extract Key Data‚ÄîPowered by AI",
    "title": "Verify Emails Instantly and Extract Key Data‚ÄîPowered by AI",
    "content": "Quick Note: . AI Mail Verification is a part of the Dataoorts AI-CRM Project. All data is securely managed and administered by Dataoorts. Email Verification, the Serverless Way ‚úî Zero commitments ‚Äì No subscriptions, no lock-ins ‚úî True pay-per-use ‚Äì Only pay for verifications you actually run ‚úî Scale freely ‚Äì From 1 to 1M+ checks with no infrastructure hassle ‚úî Credits never expire ‚Äì Use across our service ecosystem ‚úî Bulk Email Verification ‚Äì Verify millions effectively ‚úî Complete Async architecture ‚Äì Our API handles concurrent requests seamlessly ‚úî Zero Trust policy ‚Äì Under this policy we can not retain any data‚Äîwe only process it. ",
    "url": "/dataoorts_documentation/docs/verify-emails-instantly-and-extract-key-data-powered-by-ai",
    
    "relUrl": "/docs/verify-emails-instantly-and-extract-key-data-powered-by-ai"
  },"34": {
    "doc": "Get Started With X-Series GPU Instances",
    "title": "Launch X-Series Instance",
    "content": "Here are steps to launch your first x-series instance: step 1: Visit Here | Register your account and verify your email and make sure x-series instance starts with ‚Äúx_‚Äú or ‚Äúx-‚Äú. step 2: Add sufficient credit amount to start your x-series instance. step 3: Select the instance type you want to spin up, For more specifications about GPU models, visit Here. step 4: Select your DMI (learn more about DMI: Here) and Launch Instance. step 5: To access your instance, Default temporary.pem SSH key is automatically generated for instance access. However, since this key is provided by default, you should update your instance‚Äôs SSH credentials with your own key. Instructions for changing the key is Here. Note: While the instance is launching or terminating, do not close or refresh the browser. It will take a while to process everything. Super-DDRA Cluster for Hosting X-Series Instance Nodes All X-Series instances are hosted in a secure cloud environment within Tier 3 and Tier 4 data centers. The DDRA Cluster for X-Series consists of a globally distributed hybrid GPU infrastructure, integrating our own GPU racks in data centers alongside major cloud and GPU providers. Report Issue/Bug . If you encounter any bugs or issues on our cloud platform, we sincerely appreciate your efforts and time in notifying us. Please feel free to reach out to us at help@dataoorts.com. ",
    "url": "/dataoorts_documentation/docs/get-started-x-series-gpu-instances/#launch-x-series-instance",
    
    "relUrl": "/docs/get-started-x-series-gpu-instances/#launch-x-series-instance"
  },"35": {
    "doc": "Get Started With X-Series GPU Instances",
    "title": "Get Started With X-Series GPU Instances",
    "content": " ",
    "url": "/dataoorts_documentation/docs/get-started-x-series-gpu-instances/",
    
    "relUrl": "/docs/get-started-x-series-gpu-instances/"
  },"36": {
    "doc": "Get Started",
    "title": "Dataoorts AI",
    "content": "Dataoorts Serverless API Endpoint: https://cloud.dataoorts.com/api/v1 . Get Your Serverless API Credential From: https://cloud.dataoorts.com/llms . Unlock the power of serverless AI with Dataoorts! Gain seamless access to a vast collection of open-source AI models through our easy-to-use API, designed for maximum flexibility and scalability. Whether you‚Äôre exploring natural language processing, computer vision, or other advanced AI capabilities, Dataoorts has a model to fit your needs. Need a custom solution? Join our Discord community, where our team is ready to assist in creating and deploying tailored AI models just for you. Take your projects to the next level with Dataoorts‚Äô robust AI ecosystem today! . Let‚Äôs dive in and innovate together! . ",
    "url": "/dataoorts_documentation/docs/get-started/#dataoorts-ai",
    
    "relUrl": "/docs/get-started/#dataoorts-ai"
  },"37": {
    "doc": "Get Started",
    "title": "Get Started",
    "content": " ",
    "url": "/dataoorts_documentation/docs/get-started/",
    
    "relUrl": "/docs/get-started/"
  },"38": {
    "doc": "KinD Cluster",
    "title": "KinD In GC2",
    "content": "[Linux] . To Install KinD, You Need To Follow The Instructions Given Here: https://kind.sigs.k8s.io/docs/user/quick-start/ . Install Kubectl . [Linux] . Follow These Instruction: https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/ . Enable GPU Access In KinD Cluster . # Verify that everything is set up before moving further sudo apt-get update curl -O https://raw.githubusercontent.com/rajat709/Cloud-API-Builder/main/meta/kind-verify.sh &amp;&amp; chmod +x kind-verify.sh &amp;&amp; ./kind-verify.sh; status=$? &amp;&amp; rm -f kind-verify.sh . # Create a Kind Cluster --v1.27.3 kind create cluster --name dataoorts --config - &lt;&lt;EOF apiVersion: kind.x-k8s.io/v1alpha4 kind: Cluster nodes: - role: control-plane image: kindest/node:v1.27.3@sha256:3966ac761ae0136263ffdb6cfd4db23ef8a83cba8a463690e98317add2c9ba72 # required for GPU workaround extraMounts: - hostPath: /dev/null containerPath: /var/run/nvidia-container-devices/all EOF . docker exec -ti dataoorts-control-plane ln -s /sbin/ldconfig /sbin/ldconfig.real . # In order for K8s to recognize your NVIDIA device, install the K8s NVIDIA GPU operator helm repo add nvidia https://helm.ngc.nvidia.com/nvidia || true helm repo update helm install --wait --generate-name \\ -n gpu-operator --create-namespace \\ nvidia/gpu-operator --set driver.enabled=false . # Now you are all set, test your gpus by running a simple pod kubectl apply -f - &lt;&lt; EOF apiVersion: v1 kind: Pod metadata: name: cuda-vectoradd spec: restartPolicy: OnFailure containers: - name: cuda-vectoradd image: \"nvcr.io/nvidia/k8s/cuda-sample:vectoradd-cuda11.7.1-ubuntu20.04\" resources: limits: nvidia.com/gpu: 1 EOF . ‚ö°Now you‚Äôre all set! Enjoy your Kubernetes pods with GPU acceleration.‚ö° . ",
    "url": "/dataoorts_documentation/docs/kind-cluster/#kind-in-gc2",
    
    "relUrl": "/docs/kind-cluster/#kind-in-gc2"
  },"39": {
    "doc": "KinD Cluster",
    "title": "KinD Cluster",
    "content": " ",
    "url": "/dataoorts_documentation/docs/kind-cluster/",
    
    "relUrl": "/docs/kind-cluster/"
  },"40": {
    "doc": "Minikube Cluster",
    "title": "Minikube In GC2",
    "content": "[Linux] . # Download and Install Minikube # Set-Up Minikube Using the docker driver curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 sudo install minikube-linux-amd64 /usr/local/bin/minikube &amp;&amp; rm minikube-linux-amd64 . Install Kubectl [Linux] . Follow these Instruction: https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/ . Start Minikube Cluster With GPU Access . # Verify that everything is set up before moving further sudo apt-get update curl -O https://raw.githubusercontent.com/rajat709/Cloud-API-Builder/main/meta/minikube-verify.sh &amp;&amp; chmod +x minikube-verify.sh &amp;&amp; ./minikube-verify.sh; status=$? &amp;&amp; rm -f minikube-verify.sh . # Check if bpf_jit_harden is set to 0 sudo sysctl net.core.bpf_jit_harden # If it‚Äôs not 0 run: echo \"net.core.bpf_jit_harden=0\" | sudo tee -a /etc/sysctl.conf sudo sysctl -p . # Start minikube with gpus access minikube start --driver docker --container-runtime docker --gpus all . Now you‚Äôre all set! Enjoy your Kubernetes pods with GPU acceleration. üî• . ",
    "url": "/dataoorts_documentation/docs/minikube/#minikube-in-gc2",
    
    "relUrl": "/docs/minikube/#minikube-in-gc2"
  },"41": {
    "doc": "Minikube Cluster",
    "title": "Minikube Cluster",
    "content": " ",
    "url": "/dataoorts_documentation/docs/minikube/",
    
    "relUrl": "/docs/minikube/"
  },"42": {
    "doc": "Register and Get Started",
    "title": "Register and Get Started",
    "content": "Introducing AI Email Verification‚ÄîManaged by Dataoorts, the trusted name behind high-performance GPU cloud computing. Experience cutting-edge email validation, built for speed, accuracy, and scalability. Step 1: Sign Up for Dataoorts &amp; Unlock AI Email Verification Service . üöÄ Get started in seconds! Simply create your free account Here . Why sign up? . ‚úî Instant access to powerful AI email verification . ‚úî Seamless integration with Dataoorts‚Äô GPU-powered cloud . ‚úî Scalable, secure, and built for developers &amp; businesses . Note: Dataoorts‚Äô Unified Credit system lets you access all APIs and services (email verification, cloud GPU, Serverless AI, etc.) with a single credit pool. Deploy resources smarter across our entire platform. Step 2: Power Up Your Account &amp; Start Verifying! . üîë 1. Log in to your dashboard Here . üí≥ 2. Add credits: Many Options; Card Payment, UPI, PayPal, Crypto and more . üöÄ 3. Instantly access AI Email Verification . Why You‚Äôll Love This: . ‚úî 100% Serverless ‚Äì Pay only for what you use (no subscriptions no commitment!) . ‚úî No Commitments ‚Äì Credits stay valid forever . ‚úî Instant Activation ‚Äì Start verifying emails in seconds . üëâ Get started now: Dataoorts Dashboard . You are all set! Coming Next: Discover Web Interface and API Integration Ways to Verify Emails! . ",
    "url": "/dataoorts_documentation/docs/register-get-started/",
    
    "relUrl": "/docs/register-get-started/"
  },"43": {
    "doc": "Configure Firewalls and Security Groups",
    "title": "Securing Cloud GPU VM: Allowing Specific IPs and Ports with UFW &amp; iptables",
    "content": "This guide will walk you through securing your Cloud Virtual Machine (VM) by configuring its firewall to accept incoming traffic only from a defined set of IP addresses and on specific ports. This drastically improves your VM‚Äôs security by blocking unauthorized access attempts. We will be using UFW (Uncomplicated Firewall), a user-friendly front-end for iptables, to manage these firewall rules. Prerequisites . | You have an Linux Cloud VM running and are able to access it via SSH. | You have sudo privileges on the VM. | You know the specific IP addresses that need to access your VM. | You know the specific ports that need to be open for necessary services. | . Step 1: Install UFW (Uncomplicated Firewall) . If UFW is not already installed on your Ubuntu VM, you can install it using the following commands: . sudo apt update sudo apt install ufw . Step 2: Set Default Firewall Policies . UFW‚Äôs strength lies in its default deny policy. We will set the default behavior to deny all incoming connections and allow all outgoing connections. This is a fundamental security principle: only explicitly allowed traffic should be permitted. sudo ufw default deny incoming sudo ufw default allow outgoing . | sudo ufw default deny incoming: This command sets the default policy for all incoming connections to deny. This means unless a rule explicitly allows an incoming connection, it will be blocked. | sudo ufw default allow outgoing: This command sets the default policy for all outgoing connections to allow. This generally allows your VM to initiate connections to the outside world (e.g., for software updates, accessing external services), which is usually necessary. | . Step 3: Allow Specific IP Addresses and Ports . Now, we will define rules to allow incoming traffic from specific IP addresses on specific ports. The general syntax for allowing traffic from a specific IP to a specific port using UFW is: . sudo ufw allow from &lt;ALLOWED_IP&gt; to any port &lt;PORT&gt; [proto &lt;PROTOCOL&gt;] [comment \"&lt;DESCRIPTION&gt;\"] . | &lt;ALLOWED_IP&gt;: Replace this with the IP address you want to allow. This can be a single IP address (e.g., 203.0.113.5) or an IP range in CIDR notation (e.g., 192.168.1.0/24). | &lt;PORT&gt;: Replace this with the port number you want to open (e.g., 22, 80, 443, 3306). | [proto &lt;PROTOCOL&gt;]: Optionally specify the protocol, usually tcp or udp. If omitted, UFW usually defaults to tcp for common ports but it‚Äôs best to be explicit when needed (e.g., for UDP based services). | [comment ‚Äú&lt;DESCRIPTION&gt;‚Äù]: Adding a comment helps you remember why a rule was created. This is highly recommended for maintainability. | . Some Common Examples of Allow Rules: . | Allow SSH (port 22) access from a single IP address 203.0.113.5 sudo ufw allow from 203.0.113.5 to any port 22 proto tcp comment \"Allow SSH from home IP\" . | Allow HTTP (port 80) and HTTPS (port 443) access from a specific IP address 203.0.113.5 sudo ufw allow from 203.0.113.5 to any port 80 proto tcp comment \"Allow HTTP from home IP\" sudo ufw allow from 203.0.113.5 to any port 443 proto tcp comment \"Allow HTTPS from home IP\" . | Allow SSH (port 22) access from a range of IP addresses 198.51.100.0/24 (e.g., your office network) sudo ufw allow from 198.51.100.0/24 to any port 22 proto tcp comment \"Allow SSH from office network\" . | Allow MySQL/MariaDB (port 3306) access from IP 192.0.2.10 sudo ufw allow from 192.0.2.10 to any port 3306 proto tcp comment \"Allow MySQL from DB admin server\" . | Allow UDP port 53 (DNS) from a specific IP (though typically DNS queries are outgoing, this is just an example of UDP) sudo ufw allow from 203.0.113.5 to any port 53 proto udp comment \"Allow UDP DNS from home IP (example)\" . | . Repeat Step 3 for every IP address and port combination that needs to be allowed access to your VM. Step 4: Enable UFW . Crucial Precaution: Before enabling UFW, ensure you have created a rule to allow SSH access from your current IP address. If you are accessing your VM via SSH and you enable UFW without allowing your current IP on port 22 (or your custom SSH port), you will likely lose your SSH connection and be locked out. If you are unsure, as a safety measure, you can temporarily allow SSH from anywhere before enabling UFW, and then refine the rule afterward: . sudo ufw allow ssh comment \"Temporary allow SSH from anywhere for initial setup\" . After verifying your SSH access is working, you can then enable UFW: . sudo ufw enable . You will be prompted to confirm enabling the firewall. Type y and press Enter. Once UFW is enabled, it will start enforcing the rules you have defined, including the default deny incoming policy. If you temporarily allowed SSH from anywhere, now you should replace that rule with a more specific rule to allow SSH only from your known IP(s) and delete the broad ‚Äúallow ssh‚Äù rule. For example, to allow SSH only from 203.0.113.5 and remove the temporary rule: . sudo ufw allow from 203.0.113.5 to any port 22 proto tcp comment \"Allow SSH from home IP\" sudo ufw delete allow ssh # Deletes the rule that allows SSH from anywhere (if you added it) . Step 5: Verify UFW Rules and Status . To check the current status of UFW and review the configured rules, use the command: . sudo ufw status numbered . This command will display the status of UFW (active or inactive) and list all the active rules with numbers assigned to each rule. This numbered list is helpful if you need to delete a specific rule later. Example Output: . Status: active To Action From ---- ------ ---- [ 1] 22/tcp ALLOW IN 203.0.113.5 [ 2] 80/tcp ALLOW IN 203.0.113.5 [ 3] 443/tcp ALLOW IN 203.0.113.5 [ 4] 22/tcp ALLOW IN 198.51.100.0/24 . This output shows that UFW is active and the following rules are in place: . | Rule 1: Allows TCP traffic on port 22 (SSH) from IP address 203.0.113.5 | Rule 2: Allows TCP traffic on port 80 (HTTP) from IP address 203.0.113.5 | Rule 3: Allows TCP traffic on port 443 (HTTPS) from IP address 203.0.113.5 | Rule 4: Allows TCP traffic on port 22 (SSH) from the IP range 198.51.100.0/24 | . Real Case - Firewall Configuration Scenario . Let‚Äôs say you want to configure your VM with the following requirements: . | Allow SSH access only from IP addresses 203.0.113.5 and 198.51.100.10 | Allow HTTP (port 80) and HTTPS (port 443) access only from IP address 203.0.113.5 | Block all other incoming traffic | . Here are the set of ubuntu commands you would execute: . sudo apt update &amp;&amp; sudo apt install ufw # Step 1 (if needed) sudo ufw default deny incoming # Step 2 sudo ufw default allow outgoing # Step 2 #sudo ufw allow from 203.0.113.5 to any port 22 #sudo ufw allow from 203.0.113.5 to any port 80 #sudo ufw allow from 203.0.113.5 to any port 443 #sudo ufw allow from 198.51.100.10 to any port 22 sudo ufw allow from 203.0.113.5 to any port 22 proto tcp comment \"Allow SSH from home IP\" # Step 3 sudo ufw allow from 198.51.100.10 to any port 22 proto tcp comment \"Allow SSH from secondary IP\" # Step 3 sudo ufw allow from 203.0.113.5 to any port 80 proto tcp comment \"Allow HTTP from home IP\" # Step 3 sudo ufw allow from 203.0.113.5 to any port 443 proto tcp comment \"Allow HTTPS from home IP\" # Step 3 sudo ufw enable # Step 4 sudo ufw status numbered # Step 5 (Verify) . Important Notes and Best Practices: . | Lockout Prevention is Paramount: Always be extremely cautious when enabling and configuring firewalls. Ensure you have a way to access your VM even if you misconfigure the firewall (e.g., through a cloud provider‚Äôs console access). Test your rules incrementally. Add one rule at a time and verify connectivity before adding more. | IP Ranges (CIDR Notation): Use CIDR notation (e.g., 192.168.1.0/24) when you need to allow access from a range of IP addresses, such as a network. | Deleting Rules: If you need to remove a rule, use the sudo ufw delete command. You can get the rule number from the output of sudo ufw status numbered. For example, to delete rule number 1, use: sudo ufw delete 1. You can also delete rules by specifying the rule itself, e.g., sudo ufw delete allow from 203.0.113.5 to any port 22 proto tcp. | Rule Order: UFW rules are generally processed in order. The first rule that matches the incoming traffic will be applied. While UFW tries to optimize rule order, it‚Äôs generally a good practice to place more specific rules before broader ones. | Testing Your Configuration: After enabling UFW and setting up your rules, thoroughly test your setup. Try accessing your VM from the allowed IP addresses on the allowed ports. Also, try to access it from a disallowed IP address or on a disallowed port to confirm that the firewall is blocking as expected. | Comments are as Your Friends: Always use comments (comment ‚Äú\") when adding rules. This makes it much easier to understand and manage your firewall rules in the future. | Persistence: UFW rules are persistent by default. They will be automatically loaded when your VM reboots. You don‚Äôt need to take extra steps to save them. | Advanced Scenarios (Optional): For very large sets of IP addresses, consider using ipset with iptables directly, as mentioned in the more advanced section below. However, for most common use cases, UFW is sufficient and easier to manage. | . Advanced Topic: Using ‚Äòipset‚Äô for Very Large IP Sets (Optional) . If you need to manage firewall rules for a very large number of IP addresses (thousands or more), using ipset directly with iptables can be more efficient than adding individual UFW/iptables rules. ipset allows you to create named sets of IPs and then match against these sets in your iptables rules. Note: Using ipset directly requires a deeper understanding of iptables and is generally only necessary for very specific, high-scale scenarios. For most users, UFW is sufficient. If you choose to explore ipset, you would follow steps similar to these (this is a brief overview and not a complete tutorial): . | Install ipset: sudo apt install ipset | Create an ipset: sudo ipset create ALLOWED_IPS hash:ip (creates a set named ALLOWED_IPS of type hash:ip). | Add IPs to the set: sudo ipset add ALLOWED_IPS 203.0.113.5, sudo ipset add ALLOWED_IPS 198.51.100.10, etc. | Create iptables rules that use the ipset: | . sudo iptables -A INPUT -m set --match-set ALLOWED_IPS src -p tcp --dport 22 -j ACCEPT sudo iptables -A INPUT -m set --match-set ALLOWED_IPS src -p tcp --dport 80 -j ACCEPT sudo iptables -A INPUT -m set --match-set ALLOWED_IPS src -p tcp --dport 443 -j ACCEPT sudo iptables -A INPUT -j DROP # Default drop rule (similar to UFW's default deny incoming) . | Make iptables rules persistent (using iptables-persistent package if needed). | . Alternative: Using ‚Äòiptables‚Äô Directly (Advanced Users) . While UFW simplifies firewall management, you can also configure iptables directly for more granular control. However, this method is more complex and error-prone for beginners. If you are comfortable with iptables, you can achieve the same results by directly manipulating iptables rules, setting default policies, and creating ACCEPT rules for specific source IPs and destination ports. Remember to save your iptables rules to persist after a reboot if you use iptables directly. Conclusion . By following this guide, you have successfully configured your Cloud GPU VM firewalls &amp; Security Groups to allow incoming traffic only from specific IP addresses and on designated ports using UFW. This significantly enhances the security of your VM by limiting exposure to unauthorized access attempts. Remember to always test your firewall rules and maintain a record of your configuration for future management. Always prioritize security best practices and keep your system updated. ",
    "url": "/dataoorts_documentation/docs/set-up-firewall/#securing-cloud-gpu-vm-allowing-specific-ips-and-ports-with-ufw--iptables",
    
    "relUrl": "/docs/set-up-firewall/#securing-cloud-gpu-vm-allowing-specific-ips-and-ports-with-ufw--iptables"
  },"44": {
    "doc": "Configure Firewalls and Security Groups",
    "title": "Configure Firewalls and Security Groups",
    "content": " ",
    "url": "/dataoorts_documentation/docs/set-up-firewall/",
    
    "relUrl": "/docs/set-up-firewall/"
  },"45": {
    "doc": "Single email verification",
    "title": "1. Try a free trial before making any payment",
    "content": "Try It Risk-Free! . Start with our free trial - verify up to 3 emails at no cost. No credit card required. Experience our AI-powered verification firsthand! . üëâ Start Your Free Trial Now . Why try it? . ‚úì Test accuracy with your own email samples . ‚úì See instant results before committing . ‚úì Easy upgrade when you‚Äôre ready for more . Note: Free trial limited to 3 verifications per user. ",
    "url": "/dataoorts_documentation/docs/single-email-verification/#1-try-a-free-trial-before-making-any-payment",
    
    "relUrl": "/docs/single-email-verification/#1-try-a-free-trial-before-making-any-payment"
  },"46": {
    "doc": "Single email verification",
    "title": "2. Verify Unlimited Emails with Zero Hassle!",
    "content": "Hosted on Dataoorts Portal - Your one-stop solution for Deep Email verification . Key Benefits: . ‚úì Process unlimited ‚Äúasync‚Äú email verifications in less than seconds . ‚úì AI-powered accuracy with real-time results . ‚úì Simple web interface - no technical skills needed . ‚úì Enterprise-grade security for your data - Zero Trust . Perfect For: . ‚úì Marketing teams cleaning lead lists . ‚úì Developers automating verification flows . ‚úì Businesses ensuring deliverability . Get Started Now: . üëâ Verify Unlimited Emails Now . Why Choose Our Portal? . ‚úì No hidden limits or surprise fees . ‚úì Credits never expire . ‚úì Pay only for what you verify . ‚ÄúFrom small lists to millions - we scale with your needs!‚Äù . Are you a Developer? If you‚Äôre searching for an API, we also offer access to all our services with api, including AI-powered email verification. Get the API documentation Here . ",
    "url": "/dataoorts_documentation/docs/single-email-verification/#2-verify-unlimited-emails-with-zero-hassle",
    
    "relUrl": "/docs/single-email-verification/#2-verify-unlimited-emails-with-zero-hassle"
  },"47": {
    "doc": "Single email verification",
    "title": "Single email verification",
    "content": "Complete Asynchronous Architecture: Experience blazing-fast API responses! Powered by async architecture, our system effortlessly manages thousands of concurrent requests. So that your apps stay quick, scalable, and frustration-free. ",
    "url": "/dataoorts_documentation/docs/single-email-verification/",
    
    "relUrl": "/docs/single-email-verification/"
  },"48": {
    "doc": "SSH Access Fortify",
    "title": "Replacing SSH Keys on Your X-Series VMs",
    "content": "This doc will guide you through the process of replacing your existing SSH keys on your Linux VM with a new key pair. This is a common security practice, especially if your default private key is auto-generated or if you simply want to refresh your keys. If you choose not to rotate your private key and decide to stick with the default temporary.pem key, we strongly recommend configuring firewall restrictions and limiting access to a specific set of IP addresses. To configure the firewall, refer to its documentation available Here. Assumptions: . | You have SSH access to your Linux VM using your current SSH key. | Your username on the Cloud VM is ubuntu. (Default Set for X-Series Instances). | You are using a Windows machine (but the rsa-key generation steps are broadly applicable to other operating systems). | . Step 1: Generate a New SSH Key Pair on Your Local Machine (Windows Example) . First, you need to create a new SSH key pair on your local computer. This will consist of a private key (which you keep secret) and a public key (which you will upload to your VM). Open your terminal or command prompt and run the following command to generate a new RSA SSH key in PEM format with the comment ‚Äúubuntu‚Äù: . ### PowerShell ssh-keygen -t rsa -m PEM -C ubuntu . Explanation of the command: . | ssh-keygen: The SSH key generation utility. | -t rsa: Specifies the key type as RSA (a widely used and secure algorithm). | -m PEM: Specifies the key format as PEM (Privacy Enhanced Mail), the standard format for SSH keys. | -C ubuntu: This will set the default username to ubuntu (you can choose any username you prefer). | . Prompts during key generation: . | Enter file/folder/directory in which you want to save the keys, for example: C:\\Users\\rjvishwa\\Downloads\\keys\\id_rsa. | Press Enter to accept the default filename id_rsa (private key) and id_rsa.pub (public key) in the current directory (C:\\Users\\rjvishwa\\Downloads\\keys in this example). You can also enter a different filename if you wish. (Note: On Linux/Mac the keys will be saved in your home directory typically under ~/.ssh/). | | After that Enter passphrase (empty for no passphrase) | You will be prompted to enter a passphrase to protect your private key. It is highly recommended to use a strong passphrase. If your private key is compromised, the passphrase provides an extra layer of security. If you don‚Äôt want a passphrase (less secure, but more convenient), just press Enter twice to leave it blank. | . | . You will see output similar to this: . Generating public/private rsa key pair. Enter file in which to save the key (C:\\Users\\rjvishwa\\Downloads\\keys\\id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in C:\\Users\\rjvishwa\\Downloads\\keys\\id_rsa Your public key has been saved in C:\\Users\\rjvishwa\\Downloads\\keys\\id_rsa.pub The key fingerprint is: SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx ubuntu The key's randomart image is: +---[RSA 3072]----+ | o | o . | . + . | . o o | . S + . | o o * | . o + E | + . o | . | +----[SHA256]-----+ . Key Files Created: After successful generation, you will have two files in your specified directory (e.g., C:\\Users\\rjvishwa\\Downloads\\keys): . | id_rsa: This is your PRIVATE KEY. Keep this file SECRET and SECURE. Do not share it with anyone. | id_rsa.pub: This is your PUBLIC KEY. You will copy the contents of this file to your cloud ubuntu VM. | . Step 2: View and Copy Your Public Key (id_rsa.pub) . If you‚Äôre using Linux, you can simply use the cat command or open the id_rsa.pub file with nano to view its contents, and then copy the content. On a Windows machine, you can open the file using any available option, and then copy the public key for later use. Step 3: Update the Authorized Keys on Your Ubuntu VM . Backup Existing Authorized Keys, It‚Äôs a good practice to keep a backup before making changes. cd ~/.ssh cp ~/.ssh/authorized_keys ~/.ssh/authorized_keys.bak . This will create a copy of existing authorized_keys file as authorized_keys.bak file in the ~/.ssh directory of the current VM user. Edit the Authorized Keys File: . #Open the file with nano editor nano ~/.ssh/authorized_keys # When nano editor open delete all keys present . Delete all existing keys in /authorized_keys and paste your new public key content that you copied earlier (id_rsa.pub). Save and Exit, Press CTRL+O to save, then Enter, and CTRL+X to exit nano. Step 4: Test SSH Access with the New Private Key . When connecting to your VM, specify your new private key with the -i option: . # ssh -i &lt;Path_to_private_key&gt; &lt;username&gt;@&lt;x-series_vm_ip&gt; -p &lt;SSH_Port&gt; ssh -i C:\\Users\\rjvishwa\\Downloads\\keys\\id_rsa ubuntu@&lt;YOUR_VM_IP_ADDRESS&gt; -p 22 . Verify Successful Login: If everything is configured correctly, you should be able to log in to your VM without being prompted for a password. You will be logged in using SSH key authentication with your new key pair. Step 5: Remove Backup of Old Keys (If Confirmed Working) . If you are confident that your new SSH key access is working correctly, you can remove the backup of your old authorized_keys file: . cd ~/.ssh rm authorized_keys.bak . Important Security Reminders: . | Protect Your Private Key: Your private key (id_rsa) is extremely sensitive. Keep it secure and private. Do not share it with anyone, and do not accidentally upload it to public websites or repositories. | Use a Strong Passphrase: If you chose to use a passphrase for your private key, remember it and use it whenever you use your private key for SSH. | Firewall Configuration: If you choose not to replace the default temporary.pem key, you should at least configure firewall restrictions to allow access from only a limited set of specific IP addresses. | Regular Key Rotation: Consider rotating your SSH keys periodically as a security best practice. | . Congratulations! You have successfully replaced the SSH keys on your Cloud X-Series GPU VM, enhancing its security and ensuring you have control over who can access your server via SSH. Always test your SSH access immediately after making changes to your keys. ",
    "url": "/dataoorts_documentation/docs/ssh-fortify/#replacing-ssh-keys-on-your-x-series-vms",
    
    "relUrl": "/docs/ssh-fortify/#replacing-ssh-keys-on-your-x-series-vms"
  },"49": {
    "doc": "SSH Access Fortify",
    "title": "SSH Access Fortify",
    "content": " ",
    "url": "/dataoorts_documentation/docs/ssh-fortify/",
    
    "relUrl": "/docs/ssh-fortify/"
  },"50": {
    "doc": "SSH GC2 Instances",
    "title": "Access GC2 Instance ‚Äî SSH",
    "content": "You can access our GC2 instance either directly through a browser or from your local machine. Ways to Access the GC2 Instance: . | Web Based Jupyter Terminal (Depreciated) | SSH | . Web Based Terminal - Jupyter (Depreciated) . We provide direct access to a web terminal (Jupyter-based). You don‚Äôt need to set up anything. Just choose your instance type and DMI, and launch the instance. You will find a button for ‚Äò‚ÄòWeb-SSH‚Äô‚Äô for web-based terminal access. SSH . To use SSH, you need to manually set up an SSH server on the GC2 instance. You can choose either password-based or key-based authentication. Below is a quick tutorial on how to set up an SSH connection. BASH # Update everything sudo apt-get update . BASH # The openssh-server is pre-installed, but you should reinstall it if any updates are available sudo apt install -y openssh-server . BASH # Check status of ssh-server sudo service --status-all # If SSH shows a negative sign, it means the SSH server is not activated yet. You need to activate it . Before activating OpenSSH, if you want to use key-based authentication, you need to upload your public key. For this example, we will use password-based authentication, so we first set the password for the user. By default, the user is root, but you can add as many users as you want with the privileges you wish to assign. Here, we will proceed with the root user. BASH # set up password for root user sudo passwd root . BASH # Permit Root Login sudo nano /etc/ssh/sshd_config # This will open the 'ssh_config' file. You need to add the line 'PermitRootLogin Yes' . CUSTOM # Add line PermitRootLogin Yes # After that Press &lt;ctrl + O&gt; to save the modification and after that &lt;ctrl + X&gt; to close the nano editor . BASH # Now you need to start the OpenSSH service if it is not already running sudo service ssh start # After this, check if the SSH service has a plus sign indicating that it is active and running sudo service --status-all . Now you are set to SSH to your GC2 instances from anywhere using SSH. BASH # SSH into your GC2 instance ssh &lt;user&gt;@&lt;Node-Public-IP&gt; -p &lt;Node-port Forwording to your Instance port 22&gt; # If you are using key-based authentication, you will be logged in directly as &lt;user&gt; # If you are using password-based authentication, you need to type your password for &lt;user&gt; . BASH # Let's take an example! # user is 'root' # node public-ip is '16.25.96.84' # forwarded node port mapped with your instance port 22 is '7852' ssh root@16.25.96.84 -p 7852 # Now enter your 'root' user password that you set earlier, and you are all set # These configurations are one-time; you don't need to do this again . If you are comfortable with your local development environment, there is a way to connect your GC2 instance with your local machine. This allows you to leverage the comfort of your local development setup while benefiting from the performance acceleration provided by Dataoorts GC2 instances. Set-Up Guide . ",
    "url": "/dataoorts_documentation/docs/ssh-gc2-instances/#access-gc2-instance--ssh",
    
    "relUrl": "/docs/ssh-gc2-instances/#access-gc2-instance--ssh"
  },"51": {
    "doc": "SSH GC2 Instances",
    "title": "SSH GC2 Instances",
    "content": " ",
    "url": "/dataoorts_documentation/docs/ssh-gc2-instances/",
    
    "relUrl": "/docs/ssh-gc2-instances/"
  },"52": {
    "doc": "Text Generation",
    "title": "deepseek-ai/deepseek-r1-distill-qwen-32b",
    "content": "The DeepSeek-R1-Distill-Qwen-32B model, distilled from DeepSeek-R1 using Qwen2.5, surpasses o1-mini in multiple benchmarks and sets new state-of-the-art performance standards for dense models. Get Your API Credential From: https://cloud.data‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-gen#deepseek-aideepseek-r1-distill-qwen-32b",
    
    "relUrl": "/docs/text-gen#deepseek-aideepseek-r1-distill-qwen-32b"
  },"53": {
    "doc": "Text Generation",
    "title": "deepseek-ai/deepseek-math-7b-instruct",
    "content": "DeepSeekMath-Instruct 7B is a fine-tuned mathematical model based on DeepSeekMath-Base 7B. It originates from DeepSeek-Coder-v1.5 7B and undergoes additional pre-training on 500B tokens, incorporating math-related data from Common Crawl, as well as ‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-gen#deepseek-aideepseek-math-7b-instruct",
    
    "relUrl": "/docs/text-gen#deepseek-aideepseek-math-7b-instruct"
  },"54": {
    "doc": "Text Generation",
    "title": "google/gemma-3-12b-it",
    "content": "The Gemma‚ÄØ3 series excels across a wide range of text-generation and image-comprehension tasks‚Äîsuch as question‚Äëanswering, summarization, and logical reasoning. These multimodal models accept both text and image inputs and produce text outputs. They‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-gen#googlegemma-3-12b-it",
    
    "relUrl": "/docs/text-gen#googlegemma-3-12b-it"
  },"55": {
    "doc": "Text Generation",
    "title": "meta/llama-4-scout-17b-16e-instruct",
    "content": "Meta‚Äôs Llama‚ÄØ4‚ÄØScout is a native multimodal model featuring a 17-billion‚Äëparameter ‚Äúactive‚Äù layer, supported by 16 experts, and built on a mixture‚Äëof‚Äëexperts architecture. It delivers state‚Äëof‚Äëthe‚Äëart performance in both text and image understanding‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-gen#metallama-4-scout-17b-16e-instruct",
    
    "relUrl": "/docs/text-gen#metallama-4-scout-17b-16e-instruct"
  },"56": {
    "doc": "Text Generation",
    "title": "meta/llama-3.3-70b-instruct-fp8-fast",
    "content": "Llama 3.3 70B has been quantized to FP8 precision, enhancing its optimization for improved speed. Get Your API Credential From: https://cloud.dataoorts.com/ai import requests import json # Define the endpoint URL url = ‚Äòhttps://cloud.d‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-gen#metallama-33-70b-instruct-fp8-fast",
    
    "relUrl": "/docs/text-gen#metallama-33-70b-instruct-fp8-fast"
  },"57": {
    "doc": "Text Generation",
    "title": "meta/llama-3.1-70b-instruct",
    "content": "The Meta Llama 3.1 series comprises multilingual large language models that are both pretrained and instruction-tuned for generative tasks. The text-only instruction-tuned models in the Llama 3.1 collection are specifically optimized for multilingua‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-gen#metallama-31-70b-instruct",
    
    "relUrl": "/docs/text-gen#metallama-31-70b-instruct"
  },"58": {
    "doc": "Text Generation",
    "title": "meta/llama-3.1-8b-instruct",
    "content": "The Meta Llama 3.1 8B series consists of multilingual large language models that are both pretrained and instruction-tuned for generative tasks. These text-only instruction-tuned models are specifically designed for multilingual dialogue scenarios a‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-gen#metallama-31-8b-instruct",
    
    "relUrl": "/docs/text-gen#metallama-31-8b-instruct"
  },"59": {
    "doc": "Text Generation",
    "title": "meta/llama-guard-3-8b",
    "content": "Llama Guard 3, based on the Llama-3.1-8B pretrained model, is fine-tuned specifically for content safety classification. Like its earlier versions, it is designed to classify content within both LLM inputs (prompt classification) and outputs (respon‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-gen#metallama-guard-3-8b",
    
    "relUrl": "/docs/text-gen#metallama-guard-3-8b"
  },"60": {
    "doc": "Text Generation",
    "title": "qwen/qwq-32b",
    "content": "QwQ is the dedicated reasoning model within Alibaba‚Äôs Qwen family. Unlike standard instruction-tuned models, QwQ is built to think and reason, delivering superior performance on challenging tasks. In particular, QwQ‚Äë32B, the mid‚Äësized variant with a‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-gen#qwenqwq-32b",
    
    "relUrl": "/docs/text-gen#qwenqwq-32b"
  },"61": {
    "doc": "Text Generation",
    "title": "qwen/qwen2.5-coder-32b-instruct",
    "content": "Qwen2.5‚ÄëCoder is the newest code‚Äëspecialized entry in the Qwen model family (formerly known as CodeQwen), now available in six sizes‚Äî0.5B, 1.5B, 3B, 7B, 14B, and 32B parameters‚Äîto cater to developers with diverse requirements. Building on the founda‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-gen#qwenqwen25-coder-32b-instruct",
    
    "relUrl": "/docs/text-gen#qwenqwen25-coder-32b-instruct"
  },"62": {
    "doc": "Text Generation",
    "title": "qwen/qwen1.5-14b-chat-awq",
    "content": "Qwen1.5 is an enhanced iteration of Qwen, the large language model series created by Alibaba Cloud. AWQ is a highly efficient, precise, and ultra-fast low-bit weight quantization technique, currently supporting 4-bit quantization. Get Your AP‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-gen#qwenqwen15-14b-chat-awq",
    
    "relUrl": "/docs/text-gen#qwenqwen15-14b-chat-awq"
  },"63": {
    "doc": "Text Generation",
    "title": "Text Generation",
    "content": " ",
    "url": "/dataoorts_documentation/docs/text-gen",
    
    "relUrl": "/docs/text-gen"
  },"64": {
    "doc": "Image Generation",
    "title": "black-forest-labs/flux-1-schnell",
    "content": "FLUX.1 [schnell] is a rectified flow transformer with 12 billion parameters, designed to generate images from text descriptions. Get Your API Credential From: https://cloud.dataoorts.com/ai import requests import json import base64 ## ‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-to-image-generation#black-forest-labsflux-1-schnell",
    
    "relUrl": "/docs/text-to-image-generation#black-forest-labsflux-1-schnell"
  },"65": {
    "doc": "Image Generation",
    "title": "stabilityai/stable-diffusion-xl-base-1.0",
    "content": "A diffusion-based text-to-image generative model developed by Stability AI, capable of creating and altering images based on text prompts. Get Your API Credential From: https://cloud.dataoorts.com/ai import requests import json ## Defi‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-to-image-generation#stabilityaistable-diffusion-xl-base-10",
    
    "relUrl": "/docs/text-to-image-generation#stabilityaistable-diffusion-xl-base-10"
  },"66": {
    "doc": "Image Generation",
    "title": "bytedance/stable-diffusion-xl-lightning",
    "content": "SDXL-Lightning is an exceptionally fast text-to-image generation model, capable of producing high-quality 1024px images in just a few steps. Get Your API Credential From: https://cloud.dataoorts.com/ai import requests import json ## De‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-to-image-generation#bytedancestable-diffusion-xl-lightning",
    
    "relUrl": "/docs/text-to-image-generation#bytedancestable-diffusion-xl-lightning"
  },"67": {
    "doc": "Image Generation",
    "title": "lykon/dreamshaper-8-lcm",
    "content": "A Stable Diffusion model refined for improved photorealism while maintaining a broad range of capabilities. Get Your API Credential From: https://cloud.dataoorts.com/ai import requests import json ## Define the endpoint URL url = ‚Äòhttp‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/text-to-image-generation#lykondreamshaper-8-lcm",
    
    "relUrl": "/docs/text-to-image-generation#lykondreamshaper-8-lcm"
  },"68": {
    "doc": "Image Generation",
    "title": "Image Generation",
    "content": " ",
    "url": "/dataoorts_documentation/docs/text-to-image-generation",
    
    "relUrl": "/docs/text-to-image-generation"
  },"69": {
    "doc": "Potential Use Cases",
    "title": "Revolutionize Your Outreach: The Power of AI in Email Verification and Data Extraction",
    "content": "In today‚Äôs data-driven world, the quality of your email list and the information you have about your contacts can make or break your communication strategies. Bloated databases, high bounce rates, and generic outreach are all too common, leading to wasted resources and missed opportunities. Enter Artificial Intelligence ‚Äì a game-changer that‚Äôs transforming how businesses approach email verification and data extraction. AI-powered solutions offer a sophisticated, efficient, and intelligent way to ensure your messages hit the right inbox, resonate with your audience, and ultimately drive better results. This doc will delve into the multifaceted benefits of leveraging AI for these critical tasks, exploring how it can refine your database, enhance user acquisition, and empower your marketing campaigns. ",
    "url": "/dataoorts_documentation/docs/potential-usecases/#revolutionize-your-outreach-the-power-of-ai-in-email-verification-and-data-extraction",
    
    "relUrl": "/docs/potential-usecases/#revolutionize-your-outreach-the-power-of-ai-in-email-verification-and-data-extraction"
  },"70": {
    "doc": "Potential Use Cases",
    "title": "1. Superior Email Verification: Ensuring Deliverability and Eliminating Waste",
    "content": "A fundamental challenge in email marketing and communication is ensuring that your emails actually reach their intended recipients. AI-powered email verification tackles this head-on with a level of precision and adaptability that traditional methods often lack. | Identifying Deliverable and Volatile Emails: AI algorithms excel at distinguishing between valid, deliverable email addresses and those that are risky or temporary. This includes identifying ‚Äúvolatile‚Äù emails like disposable or throw-away accounts, which users often create to bypass verification processes without providing genuine information. By flagging these, AI helps you maintain a list of legitimate and engaged contacts. | Real-Time Protection: Unlike static databases, AI-powered systems can continuously monitor for new disposable email domains as they emerge, identifying subtle patterns to block them immediately. This real-time capability offers ongoing protection against bad data and potential security risks associated with temporary emails. | Advanced Detection Capabilities: AI goes beyond basic syntax checks. It can detect gibberish emails, which are more complex than simple typos, and identify spam traps ‚Äì email addresses used to identify spammers. This ensures a higher level of accuracy in your verification process. | . ",
    "url": "/dataoorts_documentation/docs/potential-usecases/#1-superior-email-verification-ensuring-deliverability-and-eliminating-waste",
    
    "relUrl": "/docs/potential-usecases/#1-superior-email-verification-ensuring-deliverability-and-eliminating-waste"
  },"71": {
    "doc": "Potential Use Cases",
    "title": "2. Database Cleansing: Say Goodbye to Bounces and Hello to Efficiency",
    "content": "A clean email database is the bedrock of any successful email strategy. High bounce rates not only mean your messages aren‚Äôt being delivered but can also severely damage your sender reputation, leading to even more emails landing in spam folders. | Minimizing Email Bounces: AI-driven email verification identifies and removes invalid, inactive, or non-existent email addresses from your lists. This significantly reduces hard bounces (permanent delivery failures) and soft bounces (temporary issues), protecting your sender score. | Improving Sender Reputation: By maintaining a clean list and reducing bounces, you signal to Internet Service Providers (ISPs) that you are a legitimate sender, increasing the likelihood that your emails will reach the primary inbox. | Cost Savings: Sending emails to invalid addresses is a waste of resources. By cleaning your list, you optimize your email marketing spend and focus your efforts on genuinely interested recipients. | . ",
    "url": "/dataoorts_documentation/docs/potential-usecases/#2-database-cleansing-say-goodbye-to-bounces-and-hello-to-efficiency",
    
    "relUrl": "/docs/potential-usecases/#2-database-cleansing-say-goodbye-to-bounces-and-hello-to-efficiency"
  },"72": {
    "doc": "Potential Use Cases",
    "title": "3. Enhanced User Sign-Up: Attracting Genuine Customers and Streamlining Onboarding",
    "content": "The user sign-up process is a critical touchpoint. AI can play a vital role in making this process smoother, more secure, and more effective in acquiring valuable users. | Protecting Your App and Acquiring Genuine Users: AI-powered email verification during sign-up helps prevent fake or fraudulent registrations by identifying and blocking disposable or invalid email addresses in real-time. This ensures that you are building a base of genuine customers or users. | Improving User Experience with Shorter Sign-Up Forms: Users often abandon lengthy registration forms. AI can help shorten these forms by requiring only an email address initially. The system can then leverage AI-powered data extraction to infer or find other necessary information linked to that email, creating a more convenient and less intrusive experience for the user. This simplified process can lead to higher conversion rates. | Personalized Onboarding: AI can analyze new customer data and user behavior to personalize the onboarding experience, making it more relevant and engaging. This can involve guiding new users with dynamic, step-by-step instructions or triggering personalized emails with relevant information. | . ",
    "url": "/dataoorts_documentation/docs/potential-usecases/#3-enhanced-user-sign-up-attracting-genuine-customers-and-streamlining-onboarding",
    
    "relUrl": "/docs/potential-usecases/#3-enhanced-user-sign-up-attracting-genuine-customers-and-streamlining-onboarding"
  },"73": {
    "doc": "Potential Use Cases",
    "title": "4. Intelligent Data Extraction: Unlocking Valuable Insights from Emails",
    "content": "Caution: The predictions made by our AI model are not always accurate. Emails are a treasure trove of data, but manually extracting this information is time-consuming and prone to errors. AI-powered data extraction automates this process, transforming unstructured email content into valuable, structured data. | Predicting Data Linked to Email Addresses: Advanced machine learning models can analyze email addresses and associated online data to predict information such as the user‚Äôs name, company, or even potential interests. This capability is invaluable for personalizing outreach and understanding your audience better. | Automating Data Entry: AI can automatically extract key information from incoming emails, such as customer inquiries, order confirmations, invoices, and contact details. This extracted data can then be seamlessly integrated into your CRM, accounting software, or other business systems, saving significant time and improving accuracy. | Streamlining Workflows: By automating data extraction, businesses can streamline various workflows, such as lead generation, customer support, and financial processing. | . ",
    "url": "/dataoorts_documentation/docs/potential-usecases/#4-intelligent-data-extraction-unlocking-valuable-insights-from-emails",
    
    "relUrl": "/docs/potential-usecases/#4-intelligent-data-extraction-unlocking-valuable-insights-from-emails"
  },"74": {
    "doc": "Potential Use Cases",
    "title": "5. Supercharging Email Campaigns and Cold Outreach",
    "content": "The combination of verified emails and extracted data, powered by AI, can dramatically improve the effectiveness of your email campaigns and cold outreach efforts. | Personalized Cold Outreach that Converts: Sending generic cold emails is rarely effective. AI allows for hyper-personalization at scale by using predicted names and other extracted data points to tailor messages to individual recipients. This personal touch significantly increases the chances of your email being opened, read, and responded to, rather than being flagged as spam. | Targeted Campaigns to Genuine, High-Scoring Emails: AI can help segment your audience based on verified email quality and engagement potential. By focusing your campaigns on genuine emails with high deliverability and engagement scores, and further personalizing these with predicted names, you can achieve significantly better results and a higher return on investment. | Optimized Send Times and Content: AI tools can analyze recipient behavior to determine the optimal times to send emails, ensuring messages arrive when recipients are most likely to engage. Furthermore, AI can assist in crafting compelling subject lines and email copy, and even help with A/B testing different versions to maximize performance. | Improved Deliverability and Reduced Spam Complaints: Sending personalized, relevant content to verified email addresses makes your emails less likely to be marked as spam. AI can also help identify and avoid trigger words or content elements that might activate spam filters. | . ",
    "url": "/dataoorts_documentation/docs/potential-usecases/#5-supercharging-email-campaigns-and-cold-outreach",
    
    "relUrl": "/docs/potential-usecases/#5-supercharging-email-campaigns-and-cold-outreach"
  },"75": {
    "doc": "Potential Use Cases",
    "title": "The Future is Intelligent Email Communication - Dataoorts Leap",
    "content": "The applications of AI-powered email verification and data extraction are vast and continually evolving. From ensuring your messages reach the right people to understanding your audience on a deeper level and personalizing your communication at scale, AI offers unprecedented opportunities to enhance efficiency, improve engagement, and drive meaningful results. By embracing these intelligent tools, businesses can move beyond outdated email practices and unlock the true potential of their email communication strategies. ",
    "url": "/dataoorts_documentation/docs/potential-usecases/#the-future-is-intelligent-email-communication---dataoorts-leap",
    
    "relUrl": "/docs/potential-usecases/#the-future-is-intelligent-email-communication---dataoorts-leap"
  },"76": {
    "doc": "Potential Use Cases",
    "title": "Potential Use Cases",
    "content": "Let‚Äôs move forward and explore the potential use cases of AI-powered email verification and data extractor. ",
    "url": "/dataoorts_documentation/docs/potential-usecases/",
    
    "relUrl": "/docs/potential-usecases/"
  },"77": {
    "doc": "X-Series Instance Documentation",
    "title": "X-Series Instance Documentation",
    "content": "Get Started With X-Series GPU Instances . Launch X-Series Instance Here are steps to launch your first x-series instance: step 1: Visit Here | Register your account and verify your email and make sure x-series instance starts with ‚Äúx_‚Äú or ‚Äúx-‚Äú. step 2: Add sufficient credit amount to‚Ä¶ . FAQs: X-Series Instance . X-Series Instance ‚Äî F.A.Qs What is DDRA ? Learn about DDRA Here . Is it necessary to secure my SSH access after launching the VM ? Yes, it is highly recommended to secure your SSH access. You should either reset the SSH key‚Ä¶ . SSH Access Fortify . Replacing SSH Keys on Your X-Series VMs This doc will guide you through the process of replacing your existing SSH keys on your Linux VM with a new key pair. This is a common security practice, especially if your default private key is auto-generat‚Ä¶ . Configure Firewalls and Security Groups . Securing Cloud GPU VM: Allowing Specific IPs and Ports with UFW &amp; iptables This guide will walk you through securing your Cloud Virtual Machine (VM) by configuring its firewall to accept incoming traffic only from a defined set of IP addresses ‚Ä¶ . ",
    "url": "/dataoorts_documentation/docs/x-series-instance-documentation/",
    
    "relUrl": "/docs/x-series-instance-documentation/"
  },"78": {
    "doc": "FAQs: X-Series Instance",
    "title": "X-Series Instance ‚Äî F.A.Qs",
    "content": "What is DDRA ? Learn about DDRA [Here](/why-and-how-dataoorts-gpu-cloud). Is it necessary to secure my SSH access after launching the VM ? Yes, it is highly recommended to secure your SSH access. You should either reset the SSH key or configure firewall rules to allow access only from authorized IPs. By default, a temporary.pem key is generated for instance access, but for enhanced security, you should replace it with your own SSH key. Detailed instructions on updating your SSH key can be found in our documentation [Here](https://dataoorts.document360.io/v1/docs/ssh-fortify). What should I do if I configured my X-Series instance firewall and security group rules to my remote IP, but my IP has changed or is lost ? If you have restricted access to your X-Series instance using specific IP addresses and those IPs have changed, you will no longer be able to access your instance. However, there‚Äôs no need to worry‚Äîwe're here to help! Simply email us at [help@dataoorts.com](help@dataoorts.com) with your VM ID, and we will reset the firewall rules to their default settings. This will restore your access without any data loss. Where My X-Series Instance Hosted ? All X-Series instances are hosted in a secure cloud environment within Tier 3 and Tier 4 data centers. The DDRA Cluster for X-Series consists of a globally distributed hybrid GPU infrastructure, integrating our own GPU racks in data centers alongside major cloud and GPU providers. Does X-Series Instance Work on DDRA ? Yes, All X-Series Instance Works on Super-DDRA Secured Cluster. What are RAMs and CPUs in Particular Instance ? RAMs and CPUs and all other resources are allocated dynamically using DDRA Technology. Is there any hidden charge ? No, what you see in the dashboard is it. Does X-Series Instance is VM-Based ? Yes, X-Series Instance is Complete VM with KVM Hypervisor Enabled, You Get Complete Access to Machine. Can I use X-Series for Gaming ? Yes, You can use all instances for gaming, video rendering and all other ethical works that required GPU compute. Can I mine Crypto In GC2 Instance ? No, we strictly prohibit any mining activity or any illegal activity. What if my balance goes down below the threshold point ? If your balance goes below $2.50, all running instances and pods are automatically scheduled for termination. So please maintain the minimum balance of $2.50 or above. Can we pause the instance rather than terminating it ? Currently, we are working on persistent storage for GC2 instances. We assure you that this will be supported very soon. What is DMI ? Learn about DMI [Here](/dmi). ",
    "url": "/dataoorts_documentation/docs/x-series-instance-faqs/#x-series-instance--faqs",
    
    "relUrl": "/docs/x-series-instance-faqs/#x-series-instance--faqs"
  },"79": {
    "doc": "FAQs: X-Series Instance",
    "title": "FAQs: X-Series Instance",
    "content": " ",
    "url": "/dataoorts_documentation/docs/x-series-instance-faqs/",
    
    "relUrl": "/docs/x-series-instance-faqs/"
  }
}
